# LLM-co-running
Concurrent Training and Serving of Large Language Models on Distributed Systems


## An illustration of Separate and Mix under concurrent workloads

- Separate training and inference
<p align="center">
  <img src="figure/mix_opportunity_separate.png" width="100%" height="100%">
</p>

- Co-locate training and inference
<p align="center">
  <img src="figure/mix_opportunity_mix.png" width="100%" height="100%">
</p>
